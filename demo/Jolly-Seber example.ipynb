{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from dhmc.dhmc_sampler import DHMCSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions to compute the posterior of the Jolly-Seber model based on the black-kneed capsid data from Seber (1982)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions 'f' and 'f_update' are used by DHMC and must have the structure as described below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jolly_seber_model import f, f_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def f(theta, req_grad=True):  \n",
    "    \"\"\"\n",
    "    Computes the log posterior density and its gradient. \n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    theta : ndarray\n",
    "    req_grad : bool\n",
    "        If True, returns the gradient along with the log density.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    logp : float\n",
    "    grad : ndarray\n",
    "    aux : Any\n",
    "        Any computed quantities that can be re-used by the \n",
    "        subsequent calls to the function 'f_updated' to save on\n",
    "        computation.\n",
    "    \"\"\"\n",
    "    \n",
    "def f_update(theta, dtheta, j, aux):  \n",
    "    \"\"\"\n",
    "    Computes the difference in the log conditional density \n",
    "    along a given parameter index 'j'.\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    theta : ndarray\n",
    "    dtheta : float\n",
    "        Amount by which the j-th parameter is updated.\n",
    "    j : int\n",
    "        Index of the parameter to update.\n",
    "    aux : Any\n",
    "        Computed quantities from the most recent call to functions\n",
    "        'f' or 'f_update' that can be re-used to save on computation.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    logp_diff : float\n",
    "    aux_new : Any\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters \"p\", \"phi\", \"U\" are concatenated into a 1-d array for running DHMC. The dictionary \"index\" stores the linear indices used internally by 'f' and 'f_update'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jolly_seber_model import pack_param, unpack_param, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of continuous and discrete parameters.\n",
    "from jolly_seber_model import n_param, n_disc, n_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick an initial state for MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi0 = .8 * np.ones(len(index[\"phi\"]))\n",
    "p0 = .15 * np.ones(len(index[\"p\"]))\n",
    "U0 = 500 * np.ones(len(index[\"U\"]))\n",
    "theta0 = pack_param(p0, phi0, U0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the DHMC sampler and test outputs of 'f' and 'f_update'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.ones(n_param)\n",
    "dhmc = DHMCSampler(f, f_update, n_disc, n_param, scale)\n",
    "\n",
    "dhmc.test_cont_grad(theta0, sd=1, n_test=10);\n",
    "_, theta, logp_fdiff, logp_diff = \\\n",
    "    dhmc.test_update(theta0, sd=10, n_test=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run discontinuous HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "n_burnin = 10 ** 2\n",
    "n_sample = 1 * 10 ** 3\n",
    "n_update = 10\n",
    "dt = .025 * np.array([.8, 1])\n",
    "nstep = [70, 85]\n",
    "\n",
    "samples, logp_samples, accept_prob, nfevals_per_itr, time_elapsed = \\\n",
    "    dhmc.run_sampler(theta0, dt, nstep, n_burnin, n_sample, \n",
    "                     seed=seed, n_update=n_update)\n",
    "dhmc_samples = samples[n_burnin:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check mixing with traceplots.\n",
    "Note the substantial uncertainty and correlation in the capture probability $p_1$ and population size $N_1$ at the 1st capture occasion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_samples, phi_samples, U_samples, N_samples = \\\n",
    "    unpack_param(dhmc_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(p_samples)\n",
    "plt.title(r\"Traceplot of capture probabilities $p_i$'s\")\n",
    "plt.ylabel(r\"$p_i$\")\n",
    "plt.xlabel('MCMC iteration')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(N_samples)\n",
    "plt.title(r\"Traceplot of population sizes $N_i$'s\")\n",
    "plt.ylabel(r\"$N_i$\")\n",
    "plt.xlabel('MCMC iteration')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUTS-Gibbs sampler for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jolly_seber_model import update_disc\n",
    "from other_samplers.nuts_sampler import nuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuts_gibbs(f, theta, dt, logp, grad, max_depth):\n",
    "    def f_cond(theta_cont):\n",
    "        logp, grad, _ = f(np.concatenate((theta_cont, theta[n_cont:])))\n",
    "        if not np.any(np.isnan(grad)):\n",
    "            grad = grad[:n_cont]\n",
    "        return logp, grad\n",
    "    theta_cont, logp, grad, nuts_accept_prob, nfevals = \\\n",
    "        nuts(f_cond, np.random.uniform(dt[0], dt[1]), theta[:n_cont], logp, grad, max_depth, warnings=False)\n",
    "    theta[:n_cont] = theta_cont\n",
    "    theta = update_disc(theta)\n",
    "    logp, grad, _ = f(theta)\n",
    "    grad = grad[:n_cont]    \n",
    "    nfevals += 1\n",
    "    return theta, logp, grad, nuts_accept_prob, nfevals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_burnin = 10 ** 2\n",
    "n_sample = 1 * 10 ** 3\n",
    "n_update = 10\n",
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "    \n",
    "# Pre-allocate\n",
    "theta = theta0.copy()\n",
    "n_per_update = math.ceil((n_sample + n_burnin) / n_update)\n",
    "nfevals_total = 0\n",
    "samples = np.zeros((n_sample + n_burnin, len(theta)))\n",
    "logp_samples = np.zeros(n_sample + n_burnin)\n",
    "accept_prob = np.zeros(n_sample + n_burnin)\n",
    "\n",
    "# Run NUTS-Gibbs\n",
    "logp, grad, _ = f(theta)\n",
    "grad = grad[:n_cont]\n",
    "for i in range(n_sample + n_burnin):\n",
    "    theta, logp, grad, accept_prob[i], nfevals = \\\n",
    "        nuts_gibbs(f, theta, dt, logp, grad, max_depth=8)\n",
    "    nfevals_total += nfevals + 1\n",
    "    samples[i, :] = theta\n",
    "    logp_samples[i] = logp\n",
    "    if (i + 1) % n_per_update == 0:\n",
    "        print('{:d} iterations have been completed.'.format(i+1))\n",
    "\n",
    "nfevals_per_itr = nfevals_total / (n_sample + n_burnin)\n",
    "print('Each iteration required {:.2f} likelihood evaluations on average.'.format(nfevals_per_itr))\n",
    "\n",
    "nuts_gibbs_samples = samples[n_burnin:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check mixing with traceplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_samples, phi_samples, U_samples, N_samples = \\\n",
    "    unpack_param(nuts_gibbs_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(p_samples)\n",
    "plt.title(r\"Traceplot of capture probabilities $p_i$'s\")\n",
    "plt.ylabel(r\"$p_i$\")\n",
    "plt.xlabel('MCMC iteration')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(N_samples)\n",
    "plt.title(r\"Traceplot of population sizes $N_i$'s\")\n",
    "plt.ylabel(r\"$p_i$\")\n",
    "plt.xlabel('MCMC iteration')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
