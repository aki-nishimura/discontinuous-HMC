{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning: Joblib (ver 0.11) seems to freeze when running this notebook on Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from dhmc.dhmc_sampler import DHMCSampler\n",
    "from benchmarking_util import summarize_sim_results\n",
    "    # Utility functions to summarize the simulation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import time\n",
    "import pickle as pkl\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions to compute the 0-1 loss posterior based on SECOM data from UCI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_and_posterior.pac_bayes_model \\\n",
    "    import y, X, f, f_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial state for MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept0 = np.log(np.mean(y == 1) / (1 - np.mean(y == 1)))\n",
    "beta0 = np.zeros(X.shape[1])\n",
    "beta0[0] = intercept0\n",
    "theta0 = beta0\n",
    "n_param = len(theta0)\n",
    "n_disc = n_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the gradient and updating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.ones(n_param)\n",
    "dhmc = DHMCSampler(f, f_update, n_disc, n_param, scale)\n",
    "dhmc.test_cont_grad(theta0, sd=.01, n_test=10);\n",
    "_, theta, logp_fdiff, logp_diff = \\\n",
    "    dhmc.test_update(theta0, sd=10, n_test=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run DHMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rep = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_burnin = 10 ** 3\n",
    "n_sample = 10 ** 4\n",
    "dt = .3 * np.array([.7, 1]) \n",
    "nstep = [20, 30] \n",
    "\n",
    "def dhmc_simulation(seed):\n",
    "    samples, logp_samples, accept_prob, nfevals_per_itr, time_elapsed = \\\n",
    "        dhmc.run_sampler(theta0, dt, nstep, n_burnin, n_sample, seed=seed)\n",
    "    samples = samples[n_burnin:, :]\n",
    "    logp_samples = logp_samples[n_burnin:]\n",
    "    summary = summarize_sim_results(\n",
    "        samples, time_elapsed, nfevals_per_itr, n_sample, n_burnin, theta0, seed\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "sim_result = Parallel(n_jobs=4)(delayed(dhmc_simulation)(i) for i in range(n_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pac_bayes_dhmc_simulation.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pkl.dump(sim_result, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Metropolis with optimal proposal covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from other_samplers.adaptive_metropolis import adap_RWMH, RWMH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_logp(theta):\n",
    "    logp, _, _ = f(theta, req_grad=False)\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an estimated covariance matrix from a long DHMC chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../mcmc_output/pac_bayes_dhmc_output.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    mcmc_output = pkl.load(file)\n",
    "theta0_rwmh = mcmc_output['samples'][-1, :]\n",
    "Sigma = mcmc_output['emp_cov']\n",
    "stepsize = 2.38 / np.sqrt(n_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_warmup = 10 ** 6\n",
    "n_sample = 10 ** 5\n",
    "thin = 100 # Total of 'n_sample * thin' iterations.\n",
    "seed = 1\n",
    "\n",
    "def met_simulation(seed):\n",
    "    # Run MH with a fixed covariance.\n",
    "    samples, accept_rate, stepsize_seq, time_elapsed = \\\n",
    "        RWMH(f_logp, theta0_rwmh, stepsize, n_warmup, n_sample, Sigma, seed, thin)\n",
    "    print('Sampling completed.')\n",
    "    samples = samples[n_burnin:, :]\n",
    "    nfevals_per_itr = 1\n",
    "    summary = summarize_sim_results(\n",
    "        samples, time_elapsed, nfevals_per_itr, n_sample, n_burnin, theta0, seed\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "sim_result = Parallel(n_jobs=2)(delayed(met_simulation)(i) for i in range(n_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pac_bayes_met_simulation.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pkl.dump(sim_result, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Metropolis-within-Gibbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../mcmc_output/pac_bayes_dhmc_output.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    mcmc_output = pkl.load(file)\n",
    "theta0 = mcmc_output['samples'][-1, :]\n",
    "Sigma = mcmc_output['emp_cov']\n",
    "cond_sd = np.diag(np.linalg.inv(Sigma)) ** -.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adap_metropolis_gibbs(theta, prop_sd, aux, n_adap, n_per_adap=10):\n",
    "    accept_rate = np.zeros((n_adap, n_param))\n",
    "    for i in range(n_adap):\n",
    "        adapt_rate = (i + 1) ** -1\n",
    "        theta, prop_sd, accept_rate[i,:], aux \\\n",
    "            = adap_metropolis_gibbs_step(theta, prop_sd, aux, adapt_rate, n_per_adap)\n",
    "    return theta, accept_rate, prop_sd, aux  \n",
    "\n",
    "def adap_metropolis_gibbs_step(theta, prop_sd, aux, adapt_rate, n_per_adap):\n",
    "    accept_prob = np.zeros((n_per_adap, n_param))\n",
    "    for i in range(n_per_adap):\n",
    "        theta, accept_prob[i,:], aux \\\n",
    "            = metropolis_gibbs_step(theta, prop_sd, aux)\n",
    "    accept_rate = np.mean(accept_prob, 0)\n",
    "    prop_sd *= np.exp(adapt_rate * (accept_rate - .441))\n",
    "    return theta, prop_sd, accept_rate, aux\n",
    "\n",
    "def metropolis_gibbs_step(theta, prop_sd, aux):\n",
    "    accept_prob = np.zeros(n_param)\n",
    "    for index in range(n_param):\n",
    "        theta, accept_prob[index], aux = \\\n",
    "            cond_metropolis_update(theta, index, prop_sd, aux)\n",
    "    return theta, accept_prob, aux\n",
    "\n",
    "def cond_metropolis_update(theta, index, prop_sd, aux):\n",
    "    # Sample from the conditional distribution imitating the optimal\n",
    "    # Metropolis proposal standard deviation.\n",
    "    dtheta = prop_sd[index] * np.random.randn()\n",
    "    logp_diff, aux_new = f_update(theta, dtheta, index, aux)\n",
    "    accept_prob = min(1, math.exp(logp_diff))\n",
    "    if accept_prob > np.random.uniform():\n",
    "        theta[index] += dtheta\n",
    "        aux = aux_new\n",
    "    return theta, accept_prob, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_adap = 2500\n",
    "n_per_adap = 10\n",
    "n_burnin = 0\n",
    "n_sample = 5 * 10 ** 4\n",
    "\n",
    "def met_gibbs_simulation(seed):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    theta = theta0.copy()\n",
    "    _, _, aux = f(theta)\n",
    "    \n",
    "    # Adapt the proposal variance for each parameter.\n",
    "    prop_sd = 2.40 * cond_sd\n",
    "    theta, accept_rate, prop_sd, aux \\\n",
    "        = adap_metropolis_gibbs(theta, prop_sd, aux, n_adap, n_per_adap)\n",
    "\n",
    "    # Sample.\n",
    "    samples = np.zeros((n_sample, n_param))\n",
    "    accept_prob = np.zeros((n_sample, n_param))\n",
    "    samples[0, :] = theta\n",
    "    tic = time.time()\n",
    "    for i in range(1, n_sample):\n",
    "        samples[i, :], accept_prob[i, :], aux \\\n",
    "            = metropolis_gibbs_step(samples[i - 1, :], prop_sd, aux)\n",
    "    # TODO: change back to 'process_time()'?\n",
    "    toc = time.time()\n",
    "    time_elapsed = toc - tic\n",
    "    print('Sampling completed.')\n",
    "    nfevals_per_itr = 1\n",
    "    summary = summarize_sim_results(\n",
    "        samples, time_elapsed, nfevals_per_itr, n_sample, n_burnin, theta0, seed\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "sim_result = Parallel(n_jobs=4)(delayed(met_gibbs_simulation)(i) for i in range(n_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pac_bayes_met_gibbs_simulation.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pkl.dump(sim_result, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
