{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle as pkl\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from dhmc.dhmc_sampler import DHMCSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SECOM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secom = pd.read_table('./secom_features.txt', sep='\\s+', header=None)\n",
    "y = pd.read_table('./secom_outcome.txt', sep='\\s+', header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove predictors with too many na's\n",
    "max_na_pred = 20\n",
    "index_many_na = np.where(secom.isnull().sum(axis=0) > max_na_pred)[0]\n",
    "secom = secom.drop(index_many_na, axis=1) \n",
    "print('{:d} features were dropped.'.format(index_many_na.size))\n",
    "\n",
    "# Remove incomplete cases\n",
    "index_drop = np.where(secom.isnull().any(axis = 1))[0]\n",
    "secom = secom.drop(index_drop, axis=0)\n",
    "y = y.drop(index_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = secom.as_matrix()\n",
    "print('Removing additional {:d} features for identifiability.'.format(np.sum(np.var(X, 0) == 0)))\n",
    "X = X[:, np.var(X, 0) > 0]\n",
    "X = (X - np.mean(X, 0)) / np.std(X, 0)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X)) # Intercept\n",
    "y = y.as_matrix().astype('float')\n",
    "\n",
    "n_param = X.shape[1]\n",
    "n_disc = n_param # No smooth conditional densities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the (cleaned) SECOM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('secom_outcome.npy')\n",
    "X = np.load('secom_design_matrix.npy') # With intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to compute the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to compute the log posterior density and its gradient.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the log posterior density and its gradient. \n",
    "def f(theta, req_grad=True):\n",
    "    \n",
    "    beta = theta\n",
    "    logp = 0\n",
    "    grad = np.zeros(len(y))\n",
    "    \n",
    "    # Contribution from the prior.\n",
    "    logp += - np.sum(beta ** 2) / 2\n",
    "    \n",
    "    # Contribution from the likelihood.\n",
    "    y_hat = np.dot(X, beta)\n",
    "    loglik = np.count_nonzero(y * y_hat > 0)\n",
    "    logp += loglik\n",
    "    \n",
    "    aux = (loglik, y_hat)\n",
    "    return logp, np.zeros(len(theta)), aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to compute the difference in the log conditional density for a given parameter index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_update(beta, dbeta, index, aux):\n",
    "    \n",
    "    j = index\n",
    "    loglik_prev, y_hat = aux\n",
    "    y_hat = y_hat + X[:,j] * dbeta\n",
    "    \n",
    "    logp_diff = (beta[j] ** 2 - (beta[j] + dbeta) ** 2) / 2\n",
    "    \n",
    "    # Contribution from the likelihood.\n",
    "    loglik = np.count_nonzero(y * y_hat > 0)\n",
    "    logp_diff += loglik - loglik_prev\n",
    "    \n",
    "    aux_new = (loglik, y_hat)\n",
    "    return logp_diff, aux_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial state for MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept0 = np.log(np.mean(y == 1) / (1 - np.mean(y == 1)))\n",
    "beta0 = np.zeros(X.shape[1])\n",
    "beta0[0] = intercept0\n",
    "theta0 = beta0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the gradient and updating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.ones(n_param)\n",
    "dhmc = DHMCSampler(f, f_update, n_disc, n_param, scale)\n",
    "dhmc.test_cont_grad(theta0, sd=.01, n_test=10);\n",
    "_, theta, logp_fdiff, logp_diff = \\\n",
    "    dhmc.test_update(theta0, sd=10, n_test=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logp, _, aux = f(theta0)\n",
    "%timeit f(theta0)\n",
    "%timeit f_update(theta0, .1, 1, aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f f f(theta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit f(theta0, opt=True)\n",
    "%timeit f(theta0, opt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi = np.dot(X.T, X)\n",
    "eig_val = np.linalg.eigvalsh(Phi)\n",
    "plt.plot(np.log10(eig_val))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "seed = 1\n",
    "n_burnin = 10 ** 2\n",
    "n_sample = 10 ** 3\n",
    "dt = .8 * np.array([.7, 1]) \n",
    "nstep = [10, 15] # [60, 75]\n",
    "samples, logp_samples, accept_prob, nfevals_per_itr, time_elapsed = \\\n",
    "    dhmc.run_sampler(theta0, dt, nstep, n_burnin, n_sample, seed=seed)\n",
    "    \n",
    "samples = samples[n_burnin:, :]\n",
    "logp_samples = logp_samples[n_burnin:]\n",
    "dhmc_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin = 10\n",
    "\n",
    "mcmc_output = {\n",
    "    'samples': samples[::thin, :],\n",
    "    'logp': logp_samples,\n",
    "    'accept_prob': accept_prob,\n",
    "    'nfevals_per_itr': nfevals_per_itr,\n",
    "    'time': time_elapsed,\n",
    "    'n_burnin': n_burnin,\n",
    "    'seed': seed,\n",
    "    'theta0': theta0,\n",
    "    'thin': thin,\n",
    "    'emp_cov': np.cov(samples.T)\n",
    "}\n",
    "\n",
    "filename = 'pac_bayes_dhmc_output.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pkl.dump(mcmc_output, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Metroplis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_metropolis import adap_RWMH, RWMH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_logp(theta):\n",
    "    logp, _, _ = f(theta, req_grad=False, opt=True)\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "n_warmup = 0 # 10 ** 4\n",
    "n_sample = 2 * 10 ** 2\n",
    "thin = 100\n",
    "seed = 1\n",
    "\n",
    "filename = 'pac_bayes_dhmc_output.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    mcmc_output = pkl.load(file)\n",
    "theta0_rwmh = mcmc_output['samples'][-1, :]\n",
    "Sigma = mcmc_output['emp_cov']\n",
    "stepsize = 2.38 / math.sqrt(n_param)\n",
    "\n",
    "# Run MH with a fixed covariance.\n",
    "samples, accept_rate, stepsize_seq, time_elapsed = \\\n",
    "    RWMH(f_logp, theta0_rwmh, stepsize, n_warmup, n_sample, Sigma, seed, thin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Metropolis-within-Gibbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pac_bayes_dhmc_output.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    mcmc_output = pkl.load(file)\n",
    "theta0_rwmh = mcmc_output['samples'][-1, :]\n",
    "Sigma = mcmc_output['emp_cov']\n",
    "cond_sd = np.diag(np.linalg.inv(Sigma)) ** -.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adap_metropolis_gibbs(theta, prop_sd, aux, n_adap, n_per_adap=10):\n",
    "    accept_rate = np.zeros((n_adap, n_param))\n",
    "    for i in range(n_adap):\n",
    "        adapt_rate = (i + 1) ** -1\n",
    "        theta, prop_sd, accept_rate[i,:], aux \\\n",
    "            = adap_metropolis_gibbs_step(theta, prop_sd, aux, adapt_rate, n_per_adap)\n",
    "    return theta, accept_rate, prop_sd, aux  \n",
    "\n",
    "def adap_metropolis_gibbs_step(theta, prop_sd, aux, adapt_rate, n_per_adap):\n",
    "    accept_prob = np.zeros((n_per_adap, n_param))\n",
    "    for i in range(n_per_adap):\n",
    "        theta, accept_prob[i,:], aux \\\n",
    "            = metropolis_gibbs_step(theta, prop_sd, aux)\n",
    "    accept_rate = np.mean(accept_prob, 0)\n",
    "    prop_sd *= np.exp(adapt_rate * (accept_rate - .441))\n",
    "    return theta, prop_sd, accept_rate, aux\n",
    "\n",
    "def metropolis_gibbs_step(theta, prop_sd, aux):\n",
    "    accept_prob = np.zeros(n_param)\n",
    "    for index in range(n_param):\n",
    "        theta, accept_prob[index], aux = \\\n",
    "            cond_metropolis_update(theta, index, prop_sd, aux)\n",
    "    return theta, accept_prob, aux\n",
    "\n",
    "def cond_metropolis_update(theta, index, prop_sd, aux):\n",
    "    # Sample from the conditional distribution imitating the optimal\n",
    "    # Metropolis proposal standard deviation.\n",
    "    dtheta = prop_sd[index] * np.random.randn()\n",
    "    logp_diff, aux_new = f_update(theta, dtheta, index, aux)\n",
    "    accept_prob = min(1, math.exp(logp_diff))\n",
    "    if accept_prob > np.random.uniform():\n",
    "        theta[index] += dtheta\n",
    "        aux = aux_new\n",
    "    return theta, accept_prob, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_adap = 10 ** 3\n",
    "prop_sd = 2.40 * cond_sd\n",
    "_, _, aux = f(theta)\n",
    "theta, accept_rate, prop_sd, aux \\\n",
    "    = adap_metropolis_gibbs(theta, prop_sd, aux, n_adap, n_per_adap=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "seed = 1\n",
    "n_burnin = 0\n",
    "n_sample = 2 * 10 ** 2\n",
    "\n",
    "np.random.seed(seed)\n",
    "theta = theta0.copy()\n",
    "_, _, aux = f(theta)\n",
    "for i in range(n_burnin):\n",
    "    theta, _, aux = metropolis_gibbs_step(theta, prop_sd, aux)\n",
    "    \n",
    "samples = np.zeros((n_sample, n_param))\n",
    "accept_prob = np.zeros((n_sample, n_param))\n",
    "samples[0, :] = theta\n",
    "for i in range(1, n_sample):\n",
    "    samples[i, :], accept_prob[i, :], aux \\\n",
    "        = metropolis_gibbs_step(samples[i - 1, :], prop_sd, aux)\n",
    "accept_rate = np.mean(accept_prob[1:,:], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accept_rate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pac_bayes_dhmc_output.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    mcmc_output = pkl.load(file)\n",
    "samples = mcmc_output['samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the summary statistics as well as their mixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.mean(np.dot(samples, X.T), 0)\n",
    "agreement = (y * y_hat > 0)\n",
    "np.mean(agreement[y == 1]), np.mean(agreement[y == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples.mean(axis=0)[1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi = np.dot(X.T, X)\n",
    "d, V = np.linalg.eigh(Phi)\n",
    "plt.plot(np.dot(samples, V[:, -10:]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_mono = mono_seq_ess(samples, normed=True)\n",
    "plot_index = np.argsort(ess_mono)[:10]\n",
    "plt.plot(samples[:, plot_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mcmc_output['logp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_mono = mono_seq_ess(samples, normed=True)\n",
    "plt.plot(np.log10(ess_mono))\n",
    "# plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look at the posterior covariance structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sqrt(np.linalg.eigvalsh(np.cov(samples.T))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.diag(Sigma)\n",
    "corr_mat = np.dot(np.diag(var ** -.5), np.dot(Sigma, np.diag(var ** -.5)))\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(corr_mat, cmap='coolwarm')\n",
    "plt.clim(-1, 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a posterior conditional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1 + np.argmax(np.abs(beta_hat[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples[:, index], bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0 # Index for plotting\n",
    "_, _, aux = f(beta_hat)\n",
    "resol = 251\n",
    "support = np.std(samples[:, index]) * np.array([-1, 1]) \n",
    "grid = np.linspace(support[0], support[1], resol)\n",
    "logp = np.array([f_update(beta_hat, dbeta, index, aux)[0] for dbeta in grid])\n",
    "density = np.exp(logp - np.max(logp))\n",
    "density /= np.sum(density * (grid[1] - grid[0]))\n",
    "\n",
    "plt.figure(figsize=(14, 4.5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(beta_hat[index] + grid, density)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(beta_hat[index] + grid, -logp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, aux = f(beta_hat)\n",
    "resol = 251\n",
    "support = np.std(samples[:, index]) * np.array([-5, 5])\n",
    "grid = beta_hat[index] + np.linspace(support[0], support[1], resol)\n",
    "def f_shifted(beta, dbeta, index):\n",
    "    beta = beta.copy()\n",
    "    beta[index] += dbeta\n",
    "    return f(beta)\n",
    "logp = np.array([f_shifted(beta_hat, dbeta, index)[0] for dbeta in grid])\n",
    "density = np.exp(logp - np.max(logp))\n",
    "plt.plot(grid, logp)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
