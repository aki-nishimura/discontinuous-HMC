{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "home_dir = '/Users/an88/'\n",
    "sys.path.insert(0, home_dir + 'Dropbox/Documents (Academic)/GitHub/NUTS (Python)/')\n",
    "sys.path.insert(0, home_dir + 'Dropbox/Documents (Academic)/GitHub/Discontinuous HMC/')\n",
    "sys.path.insert(0, home_dir + 'Dropbox/Documents (Academic)/GitHub/Discontinuous HMC/dhmc/')\n",
    "from importlib import reload\n",
    "from dhmc_sampler import DHMCSampler\n",
    "from NUTS import nuts\n",
    "from adaptive_metropolis import adap_RWMH, RWMH\n",
    "from mcmc_diagnostic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import pdb\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Jolly-Seber model with the black-kneed capsid data from Seber (1982)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the log-posterior and its gradient.\n",
    "from jolly_seber_model import f\n",
    "\n",
    "# Function to compute the difference in the log conditional density.\n",
    "from jolly_seber_model import f_update\n",
    "\n",
    "# The parameters \"p\", \"phi\", \"U\" are concatenated into a 1-d\n",
    "# array for running DHMC. The dictionary \"index\" stores the\n",
    "# linear indices used internally by 'f' and 'f_update'.\n",
    "from jolly_seber_model import pack_param, unpack_param, index\n",
    "\n",
    "# Extract the number of continuous and discrete parameters.\n",
    "n_param = np.sum([len(val) for val in index.values()])\n",
    "n_disc = len(index[\"U\"])\n",
    "n_cont = n_param - n_disc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial state for MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi0 = .8 * np.ones(len(index[\"phi\"]))\n",
    "p0 = .15 * np.ones(len(index[\"p\"]))\n",
    "U_init0 = 500\n",
    "B0 = 200 * np.ones(len(index[\"U\"]) - 1) # The number of \"births\".\n",
    "theta0 = pack_param(p0, phi0, U_init0, B0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the coordinate wise update function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.ones(n_param)\n",
    "dhmc = DHMCSampler(f, f_update, n_disc, n_param, scale)\n",
    "dhmc.test_cont_grad(theta0, sd=1, n_test=10);\n",
    "_, theta, logp_fdiff, logp_diff = \\\n",
    "    dhmc.test_update(theta0, sd=10, n_test=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an integrator for discontinuous HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(samples, logp_samples, accept_prob, nfevals_per_itr, method):\n",
    "    \n",
    "    filename = 'jolly_seber_' + method + '_test_output.pkl'\n",
    "    with open(filename, 'rb') as file:\n",
    "        samples0, logp_samples0, accept_prob0, nfevals_per_itr0 \\\n",
    "            = pkl.load(file)\n",
    "            \n",
    "    test_pass = np.allclose(samples, samples0) \\\n",
    "        and np.allclose(logp_samples, logp_samples0) \\\n",
    "        and np.allclose(accept_prob, accept_prob0) \\\n",
    "        and np.allclose(nfevals_per_itr, nfevals_per_itr0)\n",
    "        \n",
    "    if test_pass:\n",
    "        print('Test passed! The current output matches the former one.')\n",
    "    else:\n",
    "        print('Test failed....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "n_burnin = 10 ** 1\n",
    "n_sample = 1 * 10 ** 1\n",
    "n_update = 1\n",
    "dt = .025 * np.array([.8, 1])\n",
    "nstep = [70, 85]\n",
    "\n",
    "samples, logp_samples, accept_prob, nfevals_per_itr, time_elapsed = \\\n",
    "    dhmc.run_sampler(theta0, dt, nstep, n_burnin, n_sample, \n",
    "                     seed=seed, n_update=n_update)\n",
    "samples = samples[n_burnin:, :]\n",
    "logp_samples = logp_samples[n_burnin:]\n",
    "check_output(samples, logp_samples, accept_prob, nfevals_per_itr, method='dhmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_test_output = False\n",
    "method = 'dhmc'\n",
    "if update_test_output:\n",
    "    filename = 'jolly_seber_' + method + '_test_output.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        to_save = (samples, logp_samples, accept_prob, nfevals_per_itr)\n",
    "        pkl.dump(to_save, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_output = {\n",
    "    'samples': samples,\n",
    "    'logp': logp_samples,\n",
    "    'accept_prob': accept_prob,\n",
    "    'nfevals_per_itr': nfevals_per_itr,\n",
    "    'n_burnin': n_burnin,\n",
    "    'seed': seed,\n",
    "    'theta0': theta0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'jolly_seber_dhmc_output.npy'\n",
    "with open(filename, 'wb') as file:\n",
    "    pkl.dump(mcmc_output, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUTS-Gibbs sampler for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jolly_seber_model import update_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuts_gibbs(f, theta, dt, logp, grad, max_depth):\n",
    "    def f_cond(theta_cont):\n",
    "        logp, grad, _ = f(np.concatenate((theta_cont, theta[n_cont:])))\n",
    "        if not np.any(np.isnan(grad)):\n",
    "            grad = grad[:n_cont]\n",
    "        return logp, grad\n",
    "    theta_cont, logp, grad, nuts_accept_prob, nfevals = \\\n",
    "        nuts(f_cond, np.random.uniform(dt[0], dt[1]), theta[:n_cont], logp, grad, max_depth, warnings=False)\n",
    "    theta[:n_cont] = theta_cont\n",
    "    theta = update_disc(theta)\n",
    "    logp, grad, _ = f(theta)\n",
    "    grad = grad[:n_cont]    \n",
    "    nfevals += 1\n",
    "    return theta, logp, grad, nuts_accept_prob, nfevals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_burnin = 10 ** 1\n",
    "n_sample = 1 * 10 ** 1\n",
    "n_update = 1\n",
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "    \n",
    "# Pre-allocate\n",
    "theta = theta0.copy()\n",
    "n_per_update = math.ceil(n_sample / n_update)\n",
    "nfevals_total = 0\n",
    "samples = np.zeros((n_sample + n_burnin, len(theta)))\n",
    "logp_samples = np.zeros(n_sample + n_burnin)\n",
    "accept_prob = np.zeros(n_sample + n_burnin)\n",
    "\n",
    "# Run NUTS-Gibbs\n",
    "tic = time.process_time()\n",
    "logp, grad, _ = f(theta)\n",
    "grad = grad[:n_cont]\n",
    "for i in range(n_sample + n_burnin):\n",
    "    theta, logp, grad, accept_prob[i], nfevals = \\\n",
    "        nuts_gibbs(f, theta, dt, logp, grad, max_depth=8)\n",
    "    nfevals_total += nfevals + 1\n",
    "    samples[i, :] = theta\n",
    "    logp_samples[i] = logp\n",
    "    if (i + 1) % n_per_update == 0:\n",
    "        print('{:d} iterations have been completed.'.format(i+1))\n",
    "\n",
    "toc = time.process_time()\n",
    "time_elapsed = toc - tic\n",
    "time_elapsed *= n_sample / (n_sample + n_burnin) # Adjust for the burn-in time.  \n",
    "nfevals_per_itr = nfevals_total / (n_sample + n_burnin)\n",
    "print('Each iteration required {:.2f} likelihood evaluations on average.'.format(nfevals_per_itr))\n",
    "\n",
    "samples = samples[n_burnin:, :]\n",
    "logp_samples = logp_samples[n_burnin:]\n",
    "\n",
    "check_output(samples, logp_samples, accept_prob, nfevals_per_itr, method='nuts_gibbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_test_output = False\n",
    "method = 'nuts_gibbs'\n",
    "if update_test_output:\n",
    "    filename = 'jolly_seber_' + method + '_test_output.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        to_save = (samples, logp_samples, accept_prob, nfevals_per_itr)\n",
    "        pkl.dump(to_save, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = None\n",
    "mcmc_output = {\n",
    "    'samples': samples,\n",
    "    'logp': logp_samples,\n",
    "    'accept_prob': accept_prob,\n",
    "    'nfevals_per_itr': nfevals_per_itr,\n",
    "    'n_burnin': n_burnin,\n",
    "    'seed': seed,\n",
    "    'theta0': theta0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'jolly_seber_gibbs_output.npy'\n",
    "with open(filename, 'wb') as file:\n",
    "    pkl.dump(mcmc_output, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try M-H sampler with an optimal proposal variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_logp(theta):\n",
    "    logp, _, _ = f(theta, req_grad=False)\n",
    "    return logp\n",
    "\n",
    "n_warmup = 10 ** 3\n",
    "n_cov_adap = 10 ** 3\n",
    "n_adap_mcmc = 5 * 10 ** 3\n",
    "n_sample = 5 * 10 ** 3\n",
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Run adaptive MH to estimate the covariance.\n",
    "stepsize = 2.38 / math.sqrt(n_param)\n",
    "samples, accept_rate = \\\n",
    "    adap_RWMH(f_logp, theta0, stepsize, n_warmup, n_cov_adap, n_adap_mcmc)\n",
    "Sigma = np.cov(samples.T)\n",
    "\n",
    "# Run MH with a fixed covariance.\n",
    "tic = time.process_time() # Start clock\n",
    "samples, accept_rate, stepsize_seq, ave_stepsize_seq = \\\n",
    "    RWMH(f_logp, theta0, stepsize, 0, n_sample, Sigma)\n",
    "\n",
    "toc = time.process_time()\n",
    "time_elapsed = toc - tic\n",
    "print('Sampling completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_output = {\n",
    "    'samples': samples,\n",
    "    'accept_rate': accept_rate,\n",
    "    'n_warmup': n_warmup,\n",
    "    'n_cov_adap': n_cov_adap,\n",
    "    'n_adap_mcmc': n_adap_mcmc,\n",
    "    'seed': seed,\n",
    "    'theta0': theta0,\n",
    "}\n",
    "filename = 'jolly_seber_mh_output.npy'\n",
    "with open(filename, 'wb') as file:\n",
    "    pkl.dump(mcmc_output, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the MCMC output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'jolly_seber_dhmc_output.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    mcmc_output = pkl.load(file)\n",
    "samples = mcmc_output['samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequentist estimates.\n",
    "phi_hat = np.array([.649, 1.015, .867, .564, .836, .790, .651, .985, .686, .884, .771, float('nan')])\n",
    "phi_hat_sd = np.array([.114, .110, .107, .064, .075, .070, .056, .093, .080, .120, .128, float('nan')])\n",
    "N_hat = np.array([float('nan'), 511.2, 779.1, 963.0, 945.3, 882.2, 802.5, 653.6, 628.8, 478.5, 506.4, 462.8, float('nan')])\n",
    "N_hat_sd = np.array([float('nan'), 151.2, 129.3, 140.9, 125.5, 96.1, 74.8, 61.7, 61.9, 51.8, 65.8, 70.2, float('nan')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_samples, phi_samples, U_samples, N_samples = \\\n",
    "    unpack_param(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.mean(phi_samples, axis=0), phi_hat)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.std(phi_samples, axis=0), phi_hat_sd)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.mean(N_samples, 0), N_hat)).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.std(N_samples, 0), N_hat_sd)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(p_samples[:1000,:])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(p_samples[:, 0], bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(U_samples[:1000,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the correlation structure of the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_index = np.hstack(tuple([index[\"U\"][i], index[\"p\"][i]] for i in range(T - 1)))\n",
    "plt.imshow(np.corrcoef(samples[:, param_index].T), cmap='coolwarm')\n",
    "plt.clim(-1, 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_index = np.hstack(tuple([index[\"U\"][i], index[\"phi\"][i]] for i in range(T - 1)))\n",
    "plt.imshow(np.corrcoef(samples[:, param_index].T), cmap='coolwarm')\n",
    "plt.clim(-1, 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.corrcoef(U_samples.T), cmap='coolwarm')\n",
    "plt.xlabel('')\n",
    "plt.clim(-1, 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=80)\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.hist2d(logodd(p_samples[:,0]), np.log10(U_samples[:,0]), bins=20, normed=True, cmap='inferno')\n",
    "plt.xlabel(r'$\\log(q_1 / (1 - q_1))$')\n",
    "plt.ylabel(r'$\\log_{10}(N_1)$')\n",
    "plt.colorbar(ticks=[])\n",
    "plt.tight_layout()\n",
    "plt.savefig('jolly_seber_posterior_2dhist.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(np.log10(U_samples[:,2]), logit(phi_samples[:,0]), bins=20, cmap='inferno')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_index = np.hstack(tuple([index[\"phi\"][i]] for i in range(T - 1)))\n",
    "plt.imshow(np.corrcoef(samples[:, param_index].T), cmap='coolwarm')\n",
    "plt.clim(-1, 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
